version: '3.8'

# ============================================================
# Shared Airflow environment variables (reused via YAML anchor)
# ============================================================
x-airflow-env: &airflow-env
  AIRFLOW__CORE__EXECUTOR: LocalExecutor
  AIRFLOW__DATABASE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@airflow-postgres/airflow
  AIRFLOW__CORE__FERNET_KEY: ''
  AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: 'false'
  AIRFLOW__CORE__LOAD_EXAMPLES: 'false'
  AIRFLOW__API__AUTH_BACKENDS: 'airflow.api.auth.backend.basic_auth'

x-airflow-volumes: &airflow-volumes
  - ./airflow/dags:/opt/airflow/dags
  - ./airflow/logs:/opt/airflow/logs
  - ./airflow/plugins:/opt/airflow/plugins
  - ./scripts:/opt/airflow/scripts
  - ./data:/opt/airflow/data
  - ./pipeline_config.py:/opt/airflow/pipeline_config.py:ro
  - ./jne-audit-trail:/opt/airflow/jne-audit-trail:ro

services:
  # ============================================================
  # PostgreSQL Database (data)
  # ============================================================
  postgres:
    container_name: jne-postgres
    image: postgres:15-alpine
    restart: unless-stopped
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-jne_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jne_secure_password_2024}
      POSTGRES_DB: ${POSTGRES_DB:-jne_dashboard}
    ports:
      - "${POSTGRES_PORT:-5432}:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./scripts/init-db:/docker-entrypoint-initdb.d:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-jne_user} -d ${POSTGRES_DB:-jne_dashboard}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - jne-network

  # ============================================================
  # Zookeeper (required for Kafka)
  # ============================================================
  zookeeper:
    container_name: jne-zookeeper
    image: confluentinc/cp-zookeeper:7.5.0
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    networks:
      - jne-network

  # ============================================================
  # Kafka Broker
  # ============================================================
  kafka:
    container_name: jne-kafka
    image: confluentinc/cp-kafka:7.5.0
    depends_on:
      - zookeeper
    ports:
      - "${KAFKA_PORT:-9092}:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://jne-kafka:29092,PLAINTEXT_HOST://localhost:${KAFKA_PORT:-9092}
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:29092,PLAINTEXT_HOST://0.0.0.0:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'true'
    networks:
      - jne-network

  # ============================================================
  # Airflow PostgreSQL (metadata DB, separate from data DB)
  # ============================================================
  airflow-postgres:
    container_name: jne-airflow-postgres
    image: postgres:15-alpine
    environment:
      POSTGRES_USER: airflow
      POSTGRES_PASSWORD: airflow
      POSTGRES_DB: airflow
    volumes:
      - airflow_postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U airflow -d airflow"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - jne-network

  # ============================================================
  # Airflow Init (one-shot: db migrate + create admin user)
  # ============================================================
  airflow-init:
    container_name: jne-airflow-init
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-postgres:
        condition: service_healthy
    environment:
      <<: *airflow-env
      _AIRFLOW_ADMIN_USER: ${AIRFLOW_ADMIN_USER:-admin}
      _AIRFLOW_ADMIN_PASSWORD: ${AIRFLOW_ADMIN_PASSWORD:-admin}
    volumes: *airflow-volumes
    command: bash -c "airflow db migrate && airflow users create --username $$_AIRFLOW_ADMIN_USER --password $$_AIRFLOW_ADMIN_PASSWORD --firstname Admin --lastname User --role Admin --email admin@jne.local || true"
    restart: "no"
    networks:
      - jne-network

  # ============================================================
  # Data Init (one-shot: load CSV/Excel + unify + transform)
  # Runs automatically on first 'docker compose up'.
  # Solves the chicken-and-egg: data is ready before Airflow DAGs run.
  # ============================================================
  data-init:
    container_name: jne-data-init
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      POSTGRES_USER: ${POSTGRES_USER:-jne_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jne_secure_password_2024}
      POSTGRES_DB: ${POSTGRES_DB:-jne_dashboard}
      DB_HOST: jne-postgres
      DB_PORT: "5432"
    volumes: *airflow-volumes
    command: bash -c "python /opt/airflow/scripts/etl/load_data.py --csv-dir /opt/airflow/data/raw/csv --excel-file /opt/airflow/data/raw/JNE_RAW_COMBINED.xlsx && python /opt/airflow/scripts/transformations/transform_tables.py"
    restart: "no"
    networks:
      - jne-network

  # ============================================================
  # Airflow Webserver
  # ============================================================
  airflow-webserver:
    container_name: jne-airflow-webserver
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-init:
        condition: service_completed_successfully
      postgres:
        condition: service_healthy
      kafka:
        condition: service_started
    environment:
      <<: *airflow-env
      AIRFLOW__WEBSERVER__RBAC: "True"
      POSTGRES_USER: ${POSTGRES_USER:-jne_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jne_secure_password_2024}
      POSTGRES_DB: ${POSTGRES_DB:-jne_dashboard}
      DB_HOST: jne-postgres
      DB_PORT: "5432"
    volumes: *airflow-volumes
    ports:
      - "${AIRFLOW_PORT:-8080}:8080"
    command: webserver
    networks:
      - jne-network

  # ============================================================
  # Airflow Scheduler
  # ============================================================
  airflow-scheduler:
    container_name: jne-airflow-scheduler
    build:
      context: .
      dockerfile: Dockerfile.airflow
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    environment:
      <<: *airflow-env
      POSTGRES_USER: ${POSTGRES_USER:-jne_user}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-jne_secure_password_2024}
      POSTGRES_DB: ${POSTGRES_DB:-jne_dashboard}
      DB_HOST: jne-postgres
      DB_PORT: "5432"
    volumes: *airflow-volumes
    command: scheduler
    networks:
      - jne-network

  # ============================================================
  # pgAdmin - Web-based PostgreSQL management
  # ============================================================
  pgadmin:
    container_name: jne-pgadmin
    image: dpage/pgadmin4:latest
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: ${PGADMIN_EMAIL:-admin@admin.com}
      PGADMIN_DEFAULT_PASSWORD: ${PGADMIN_PASSWORD:-admin123}
      PGADMIN_CONFIG_SERVER_MODE: 'False'
    ports:
      - "${PGADMIN_PORT:-5050}:80"
    volumes:
      - pgadmin_data:/var/lib/pgadmin
    depends_on:
      postgres:
        condition: service_healthy
    networks:
      - jne-network

# Persistent storage volumes
volumes:
  postgres_data:
    name: jne-postgres-data
  pgadmin_data:
    name: jne-pgadmin-data
  airflow_postgres_data:

# Docker network for service communication
networks:
  jne-network:
    name: jne-pipeline-network
    driver: bridge
